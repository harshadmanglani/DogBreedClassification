{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Input\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained = InceptionV3(input_shape = (100, 100, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in pre_trained.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "x = layers.Flatten()(pre_trained.output)\n",
    "x = layers.Dense(1024, activation = 'relu')(x)\n",
    "x = layers.Dropout(0.05)(x)\n",
    "x = layers.Dense(500, activation = 'relu')(x)\n",
    "x = layers.Dense(120, activation = 'softmax')(x)\n",
    "model = Model(pre_trained.input, x)\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper parameters\n",
    "batch_size = 8\n",
    "kernel_size = (2, 2)\n",
    "filters = 64\n",
    "epochs = 200\n",
    "train_dir = #refer to data preprocessing script to set this path\n",
    "test_dir =  #refer to data preprocessing script to set this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rescale = 1./255, \n",
    "                shear_range = 0.2, \n",
    "                horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_dir, \n",
    "                                              batch_size = batch_size,\n",
    "                                              target_size = (100, 100),\n",
    "                                              color_mode = 'rgb',\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "test_set = validate_datagen.flow_from_directory(test_dir, \n",
    "                                                batch_size = batch_size,\n",
    "                                                target_size = (100, 100),\n",
    "                                                color_mode = 'rgb',\n",
    "                                                class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added features for accurate and optimized training\n",
    "# a check point callback to save our best weights\n",
    "filepath = #set path\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_accuracy', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='max', \n",
    "                             save_weights_only=False)\n",
    "\n",
    "# a reducing lr callback to reduce lr when val_loss doesn't increase\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                   patience=1, verbose=1, mode='min',\n",
    "                                   min_delta=0.0001, cooldown=2, min_lr=1e-7)\n",
    "\n",
    "# for early stop\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_set, \n",
    "          epochs = epochs, \n",
    "          validation_data = test_set,\n",
    "          validation_steps = 50,\n",
    "          verbose = 1, \n",
    "          steps_per_epoch = 1000, \n",
    "          callbacks=[checkpoint, reduce_lr, early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
